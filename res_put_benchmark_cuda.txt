GPUMPI: Using 2 mpi processes with 2 blocks and 1 threads on GPU
GPUMPI: Max active blocks per multiprocessor 28 (for 1 thread(s) per block)
GPUMPI: Max number of blocks is 168 (for 1 thread(s) per block)
GPUMPI: memFree = 4082106368, memTotal = 4234215424
GPUMPI: Heap memory requirements are not specified
GPUMPI: Using 80 % of free memory for the heap
GPUMPI: Requested heap memory size is 3265685094 bytes
Using 2 threads (1 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 2 threads (1 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
GPUMPI: no errors occured
# 1 128 100 0.000196
# 1 128 100 0.000196
# 1 128 100 0.000196
GPUMPI: Using 10 mpi processes with 10 blocks and 1 threads on GPU
GPUMPI: Max active blocks per multiprocessor 28 (for 1 thread(s) per block)
GPUMPI: Max number of blocks is 168 (for 1 thread(s) per block)
GPUMPI: memFree = 4082106368, memTotal = 4234215424
GPUMPI: Heap memory requirements are not specified
GPUMPI: Using 80 % of free memory for the heap
GPUMPI: Requested heap memory size is 3265685094 bytes
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 10 threads (5 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000203
# 5 128 100 0.000215
# 5 128 100 0.000214
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000203
# 5 128 100 0.000218
# 5 128 100 0.000234
# 5 128 100 0.000195
# 5 128 100 0.000200
# 5 128 100 0.000205
# 5 128 100 0.000230
# 5 128 100 0.000290
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000205
# 5 128 100 0.000229
# 5 128 100 0.000293
# 5 128 100 0.000195
# 5 128 100 0.000200
# 5 128 100 0.000205
# 5 128 100 0.000237
# 5 128 100 0.000295
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000205
# 5 128 100 0.000291
# 5 128 100 0.000235
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000205
# 5 128 100 0.000233
# 5 128 100 0.000290
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000205
# 5 128 100 0.000230
# 5 128 100 0.000296
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000203
# 5 128 100 0.000200
# 5 128 100 0.000205
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000203
# 5 128 100 0.000213
# 5 128 100 0.000213
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000202
# 5 128 100 0.000212
# 5 128 100 0.000213
# 5 128 100 0.000194
# 5 128 100 0.000199
# 5 128 100 0.000202
# 5 128 100 0.000211
# 5 128 100 0.000212
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000202
# 5 128 100 0.000213
# 5 128 100 0.000238
# 5 128 100 0.000195
# 5 128 100 0.000200
# 5 128 100 0.000205
# 5 128 100 0.000230
# 5 128 100 0.000293
# 5 128 100 0.000195
# 5 128 100 0.000200
# 5 128 100 0.000205
# 5 128 100 0.000222
# 5 128 100 0.000305
# 5 128 100 0.000195
# 5 128 100 0.000200
# 5 128 100 0.000205
# 5 128 100 0.000224
# 5 128 100 0.000287
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000205
# 5 128 100 0.000228
# 5 128 100 0.000296
# 5 128 100 0.000195
# 5 128 100 0.000199
# 5 128 100 0.000204
# 5 128 100 0.000296
# 5 128 100 0.000224
GPUMPI: no errors occured
# 5 128 100 0.000194
# 5 128 100 0.000199
# 5 128 100 0.000204
# 5 128 100 0.000225
# 5 128 100 0.000308
GPUMPI: Using 20 mpi processes with 20 blocks and 1 threads on GPU
GPUMPI: Max active blocks per multiprocessor 28 (for 1 thread(s) per block)
GPUMPI: Max number of blocks is 168 (for 1 thread(s) per block)
GPUMPI: memFree = 4082106368, memTotal = 4234215424
GPUMPI: Heap memory requirements are not specified
GPUMPI: Using 80 % of free memory for the heap
GPUMPI: Requested heap memory size is 3265685094 bytes
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 20 threads (10 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
# 10 128 100 0.000211
# 10 128 100 0.000195
# 10 128 100 0.000211
# 10 128 100 0.000211
# 10 128 100 0.000223
# 10 128 100 0.000212
# 10 128 100 0.000212
# 10 128 100 0.000212
# 10 128 100 0.000212
# 10 128 100 0.000213
# 10 128 100 0.000199
# 10 128 100 0.000195
# 10 128 100 0.000223
# 10 128 100 0.000240
# 10 128 100 0.000528
# 10 128 100 0.000220
# 10 128 100 0.000203
# 10 128 100 0.000284
# 10 128 100 0.000248
# 10 128 100 0.000439
# 10 128 100 0.000199
# 10 128 100 0.000233
# 10 128 100 0.000195
# 10 128 100 0.000233
# 10 128 100 0.000582
# 10 128 100 0.000212
# 10 128 100 0.000205
# 10 128 100 0.000293
# 10 128 100 0.000256
# 10 128 100 0.000415
# 10 128 100 0.000214
# 10 128 100 0.000195
# 10 128 100 0.000238
# 10 128 100 0.000238
# 10 128 100 0.000590
# 10 128 100 0.000197
# 10 128 100 0.000197
# 10 128 100 0.000283
# 10 128 100 0.000244
# 10 128 100 0.000540
# 10 128 100 0.000199
# 10 128 100 0.000195
# 10 128 100 0.000211
# 10 128 100 0.000210
# 10 128 100 0.000232
# 10 128 100 0.000208
# 10 128 100 0.000206
# 10 128 100 0.000213
# 10 128 100 0.000212
# 10 128 100 0.000212
# 10 128 100 0.000196
# 10 128 100 0.000197
# 10 128 100 0.000202
# 10 128 100 0.000202
# 10 128 100 0.000222
# 10 128 100 0.000199
# 10 128 100 0.000201
# 10 128 100 0.000205
# 10 128 100 0.000204
# 10 128 100 0.000224
# 10 128 100 0.000212
# 10 128 100 0.000212
# 10 128 100 0.000212
# 10 128 100 0.000195
# 10 128 100 0.000270
# 10 128 100 0.000213
# 10 128 100 0.000213
# 10 128 100 0.000214
# 10 128 100 0.000213
# 10 128 100 0.000214
# 10 128 100 0.000200
# 10 128 100 0.000196
# 10 128 100 0.000246
# 10 128 100 0.000233
# 10 128 100 0.000514
# 10 128 100 0.000247
# 10 128 100 0.000201
# 10 128 100 0.000247
# 10 128 100 0.000216
# 10 128 100 0.000267
# 10 128 100 0.000195
# 10 128 100 0.000203
# 10 128 100 0.000224
# 10 128 100 0.000261
# 10 128 100 0.000523
# 10 128 100 0.000219
# 10 128 100 0.000206
# 10 128 100 0.000302
# 10 128 100 0.000224
# 10 128 100 0.000347
GPUMPI: no errors occured
GPUMPI: Using 30 mpi processes with 30 blocks and 1 threads on GPU
GPUMPI: Max active blocks per multiprocessor 28 (for 1 thread(s) per block)
GPUMPI: Max number of blocks is 168 (for 1 thread(s) per block)
GPUMPI: memFree = 4082106368, memTotal = 4234215424
GPUMPI: Heap memory requirements are not specified
GPUMPI: Using 80 % of free memory for the heap
GPUMPI: Requested heap memory size is 3265685094 bytes
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 30 threads (15 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
# 15 128 100 0.000198
# 15 128 100 0.000203
# 15 128 100 0.000202
# 15 128 100 0.000203
# 15 128 100 0.000204
# 15 128 100 0.000202
# 15 128 100 0.000202
# 15 128 100 0.000204
# 15 128 100 0.000205
# 15 128 100 0.000203
# 15 128 100 0.000203
# 15 128 100 0.000207
# 15 128 100 0.000209
# 15 128 100 0.000210
# 15 128 100 0.000208
# 15 128 100 0.000204
# 15 128 100 0.000208
# 15 128 100 0.000199
# 15 128 100 0.000215
# 15 128 100 0.000209
# 15 128 100 0.000218
# 15 128 100 0.000297
# 15 128 100 0.000349
# 15 128 100 0.000209
# 15 128 100 0.000209
# 15 128 100 0.000255
# 15 128 100 0.000352
# 15 128 100 0.000478
# 15 128 100 0.000554
# 15 128 100 0.000693
# 15 128 100 0.000211
# 15 128 100 0.000205
# 15 128 100 0.000199
# 15 128 100 0.000205
# 15 128 100 0.000204
# 15 128 100 0.000205
# 15 128 100 0.000211
# 15 128 100 0.000329
# 15 128 100 0.000211
# 15 128 100 0.000261
# 15 128 100 0.000206
# 15 128 100 0.000374
# 15 128 100 0.000570
# 15 128 100 0.000773
# 15 128 100 0.000630
# 15 128 100 0.000205
# 15 128 100 0.000204
# 15 128 100 0.000204
# 15 128 100 0.000198
# 15 128 100 0.000204
# 15 128 100 0.000204
# 15 128 100 0.000206
# 15 128 100 0.000300
# 15 128 100 0.000205
# 15 128 100 0.000205
# 15 128 100 0.000205
# 15 128 100 0.000357
# 15 128 100 0.000438
# 15 128 100 0.000439
# 15 128 100 0.000441
# 15 128 100 0.000217
# 15 128 100 0.000198
# 15 128 100 0.000216
# 15 128 100 0.000217
# 15 128 100 0.000217
# 15 128 100 0.000217
# 15 128 100 0.000217
# 15 128 100 0.000217
# 15 128 100 0.000217
# 15 128 100 0.000219
# 15 128 100 0.000218
# 15 128 100 0.000217
# 15 128 100 0.000222
# 15 128 100 0.000224
# 15 128 100 0.000218
GPUMPI: no errors occured
GPUMPI: Using 40 mpi processes with 40 blocks and 1 threads on GPU
GPUMPI: Max active blocks per multiprocessor 28 (for 1 thread(s) per block)
GPUMPI: Max number of blocks is 168 (for 1 thread(s) per block)
GPUMPI: memFree = 4082106368, memTotal = 4234215424
GPUMPI: Heap memory requirements are not specified
GPUMPI: Using 80 % of free memory for the heap
GPUMPI: Requested heap memory size is 3265685094 bytes
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 40 threads (20 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
GPUMPI: malloc failed to allocate 4 bytes on device
GPUMPI: DEVICE-SIDE ABORT
GPUMPI: __gpu_assert FAILED /home/yuhzhang/workspace/gpu_mpi/gpu_libs/gpu_libc/device_vector.cuh:15 'ptr' block <18,0,0> thread <0,0,0>
GPUMPI: Using 50 mpi processes with 50 blocks and 1 threads on GPU
GPUMPI: Max active blocks per multiprocessor 28 (for 1 thread(s) per block)
GPUMPI: Max number of blocks is 168 (for 1 thread(s) per block)
GPUMPI: memFree = 4082106368, memTotal = 4234215424
GPUMPI: Heap memory requirements are not specified
GPUMPI: Using 80 % of free memory for the heap
GPUMPI: Requested heap memory size is 3265685094 bytes
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
Using 50 threads (25 sender) to put 128 double, to collect 100 data,  each datapoint is averaged over 100 samples
# 25 128 100 0.000311
# 25 128 100 0.000210
# 25 128 100 0.000229
# 25 128 100 0.000197
# 25 128 100 0.000214
# 25 128 100 0.000212
# 25 128 100 0.000210
# 25 128 100 0.000211
# 25 128 100 0.000214
# 25 128 100 0.000213
# 25 128 100 0.000434
# 25 128 100 0.000211
# 25 128 100 0.000430
# 25 128 100 0.000215
# 25 128 100 0.000435
# 25 128 100 0.000432
# 25 128 100 0.000212
# 25 128 100 0.000214
# 25 128 100 0.000432
# 25 128 100 0.000214
# 25 128 100 0.000432
# 25 128 100 0.000438
# 25 128 100 0.000435
# 25 128 100 0.000434
# 25 128 100 0.000437
# 25 128 100 0.000211
# 25 128 100 0.000197
# 25 128 100 0.000211
# 25 128 100 0.000204
# 25 128 100 0.000200
# 25 128 100 0.000216
# 25 128 100 0.000213
# 25 128 100 0.000199
# 25 128 100 0.000216
# 25 128 100 0.000211
# 25 128 100 0.000215
# 25 128 100 0.000216
# 25 128 100 0.000213
# 25 128 100 0.000215
# 25 128 100 0.000202
# 25 128 100 0.000213
# 25 128 100 0.000216
# 25 128 100 0.000216
# 25 128 100 0.000217
# 25 128 100 0.000216
# 25 128 100 0.000218
# 25 128 100 0.000237
# 25 128 100 0.000218
# 25 128 100 0.000219
# 25 128 100 0.000219
# 25 128 100 0.000204
# 25 128 100 0.000197
# 25 128 100 0.000213
# 25 128 100 0.000213
# 25 128 100 0.000212
# 25 128 100 0.000199
# 25 128 100 0.000215
# 25 128 100 0.000213
# 25 128 100 0.000213
# 25 128 100 0.000218
# 25 128 100 0.000216
# 25 128 100 0.000202
# 25 128 100 0.000219
# 25 128 100 0.000215
# 25 128 100 0.000217
# 25 128 100 0.000218
# 25 128 100 0.000219
# 25 128 100 0.000216
# 25 128 100 0.000218
# 25 128 100 0.000217
# 25 128 100 0.000219
# 25 128 100 0.000219
# 25 128 100 0.000219
# 25 128 100 0.000222
# 25 128 100 0.000219
GPUMPI: no errors occured
